{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eJ-TqgDJnWerAu0x0KX6tUWpBkeH2gc_",
      "authorship_tag": "ABX9TyP+zzPXmsjZzlavFEPUKT3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SingularityNET-Archive/LLM-Development/blob/main/snet_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A script to take a JSON file and clean it up"
      ],
      "metadata": {
        "id": "TwzgzP9q5hGZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "22a2ROUquT2K"
      },
      "outputs": [],
      "source": [
        "# A script to take a JSON file and clean it up\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "def clean_json(input_file, output_file):\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding='utf-8') as f:\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON: {e}\")\n",
        "                # Attempt to fix common JSON errors (e.g., trailing commas)\n",
        "                try:\n",
        "                    data = json.loads(re.sub(r\",\\s*\\]\", \"]\", re.sub(r\",\\s*}\", \"}\", f.read())))\n",
        "                except json.JSONDecodeError as e2:\n",
        "                    print(f\"Could not fix JSON errors, error is: {e2}\")\n",
        "                    return\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Example cleaning operations (customize as needed)\n",
        "    if isinstance(data, dict):\n",
        "        for key, value in list(data.items()):  # Iterate through a copy to allow deletion\n",
        "          if value is None:\n",
        "            del data[key]\n",
        "          if isinstance(value, str):\n",
        "            data[key] = value.strip()\n",
        "          if isinstance(value, dict):\n",
        "            # Recursively call the clean_json for nested dictionaries\n",
        "            data[key] = clean_json_helper(value)\n",
        "\n",
        "    elif isinstance(data, list):\n",
        "        for i in range(len(data)):\n",
        "            if isinstance(data[i], dict):\n",
        "                data[i] = clean_json_helper(data[i])\n",
        "            elif isinstance(data[i], str):\n",
        "                data[i] = data[i].strip()\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        json.dump(data, outfile, indent=4)\n",
        "\n",
        "def clean_json_helper(data):\n",
        "\n",
        "    # Example cleaning operations for nested dictionaries (customize as needed)\n",
        "    if isinstance(data, dict):\n",
        "      for key, value in list(data.items()):  # Iterate through a copy to allow deletion\n",
        "        if value is None:\n",
        "          del data[key]\n",
        "        if isinstance(value, str):\n",
        "          data[key] = value.strip()\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "input_file = \"/content/drive/MyDrive/Colab Notebooks/meeting-summaries-by-id.json\" # Replace with your input file\n",
        "output_file = \"output.json\"  # Replace with your desired output file\n",
        "clean_json(input_file, output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Take output.json file and check it is well formed"
      ],
      "metadata": {
        "id": "tP1pz_rnuij-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take output.json file and check it is well formed\n",
        "\n",
        "import json\n",
        "\n",
        "def is_valid_json(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            json.load(f)\n",
        "        return True\n",
        "    except json.JSONDecodeError:\n",
        "        return False\n",
        "\n",
        "# Example usage\n",
        "file_path = \"output.json\"  # Replace with the actual path to your file\n",
        "if is_valid_json(file_path):\n",
        "    print(f\"The file '{file_path}' is a valid JSON file.\")\n",
        "else:\n",
        "    print(f\"The file '{file_path}' is not a valid JSON file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2j_gpTw2cHO",
        "outputId": "7c52a4dd-d786-4d2e-fb96-0a3b6dbce942"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file 'output.json' is a valid JSON file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify the entities and relationships in output.json using NLP and output in nlp.txt"
      ],
      "metadata": {
        "id": "jQ7o4Txj549E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the entities and relationships in output.json using NLP and output in nlp.txt\n",
        "\n",
        "import json\n",
        "import spacy\n",
        "\n",
        "# Load a spaCy model (you might need to download one: python -m spacy download en_core_web_sm)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities_and_relationships(json_file, output_file):\n",
        "    try:\n",
        "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{json_file}' not found.\")\n",
        "        return\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Invalid JSON in file '{json_file}'.\")\n",
        "        return\n",
        "\n",
        "    entities_and_relationships = []\n",
        "\n",
        "    def process_data(data):\n",
        "      if isinstance(data, dict):\n",
        "        for key, value in data.items():\n",
        "          if isinstance(value, str):\n",
        "            doc = nlp(value)\n",
        "            for ent in doc.ents:\n",
        "              entities_and_relationships.append({\"entity\": ent.text, \"label\": ent.label_,\"context\":key})\n",
        "\n",
        "            for token in doc:\n",
        "                if token.dep_ == \"ROOT\":\n",
        "                   entities_and_relationships.append({\"relationship\": token.text, \"context\": key})\n",
        "          elif isinstance(value, (dict, list)):\n",
        "            process_data(value)\n",
        "\n",
        "      elif isinstance(data, list):\n",
        "        for item in data:\n",
        "           process_data(item)\n",
        "\n",
        "\n",
        "    process_data(data)\n",
        "\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
        "            json.dump(entities_and_relationships, outfile, indent=4)\n",
        "        print(f\"Entities and relationships extracted to '{output_file}'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to file: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "input_json_file = \"output.json\"  # Replace with the path to your JSON file\n",
        "output_txt_file = \"nlp.txt\"  # Replace with the desired output file name\n",
        "extract_entities_and_relationships(input_json_file, output_txt_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhxOe1iR2oox",
        "outputId": "fd590913-9c68-4c92-ff45-fda2d1012b51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities and relationships extracted to 'nlp.txt'\n"
          ]
        }
      ]
    }
  ]
}
